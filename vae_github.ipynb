{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae-github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPORWPauFjgDbkCAxgx03eD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GohVh/vae/blob/main/vae_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "Uti1QqufFNd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf '/content/sample_data'"
      ],
      "metadata": {
        "id": "kLj0Rqe7s0u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "eKbuRa8Vs5DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -av 'copy your dataset from gdrive'"
      ],
      "metadata": {
        "id": "JYAsn_rqs6tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/model'\n",
        "!mkdir '/content/result'"
      ],
      "metadata": {
        "id": "63WOHUjwrj-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize and import package"
      ],
      "metadata": {
        "id": "dwL4KgbCFUw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torch import nn, Tensor\n",
        "from torchvision import utils\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "G1WCNkwQMteA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Design DL model"
      ],
      "metadata": {
        "id": "VidWwm27FaUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variational Autoencoders (ResNet18Encoder-ResNet18Decoder)"
      ],
      "metadata": {
        "id": "UmTUDLckcV3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResizeConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, scale_factor, mode='nearest'):\n",
        "        super().__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "        self.mode = mode\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class ResNet18Enc(nn.Module):\n",
        "  def __init__(self, z_dim=32):\n",
        "    super().__init__()\n",
        "    self.z_dim=z_dim\n",
        "    self.ResNet18 = models.resnet18(pretrained=True)\n",
        "    self.num_features = self.ResNet18.fc.in_features\n",
        "    self.ResNet18.fc = nn.Linear(self.num_features, 2 * self.z_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.ResNet18(x)\n",
        "    mu = x[:, :self.z_dim]\n",
        "    logvar = x[:, self.z_dim:]\n",
        "    return mu, logvar\n",
        "\n",
        "class BasicBlockDec(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        planes = int(in_planes/stride)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(in_planes)\n",
        "        # self.bn1 could have been placed here, but that messes up the order of the layers when printing the class\n",
        "\n",
        "        if stride == 1:\n",
        "            self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "            self.bn1 = nn.BatchNorm2d(planes)\n",
        "            self.shortcut = nn.Sequential()\n",
        "        else:\n",
        "            self.conv1 = ResizeConv2d(in_planes, planes, kernel_size=3, scale_factor=stride)\n",
        "            self.bn1 = nn.BatchNorm2d(planes)\n",
        "            self.shortcut = nn.Sequential(\n",
        "                ResizeConv2d(in_planes, planes, kernel_size=3, scale_factor=stride),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn2(self.conv2(x)))\n",
        "        out = self.bn1(self.conv1(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = torch.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet18Dec(nn.Module):\n",
        "\n",
        "    def __init__(self, num_Blocks=[2, 2, 2, 2], z_dim=32, nc=3):\n",
        "        super().__init__()\n",
        "        self.in_planes = 512\n",
        "\n",
        "        self.linear = nn.Linear(z_dim, 512)\n",
        "\n",
        "        self.layer4 = self._make_layer(BasicBlockDec, 256, num_Blocks[3], stride=2)\n",
        "        self.layer3 = self._make_layer(BasicBlockDec, 128, num_Blocks[2], stride=2)\n",
        "        self.layer2 = self._make_layer(BasicBlockDec, 64, num_Blocks[1], stride=2)\n",
        "        self.layer1 = self._make_layer(BasicBlockDec, 64, num_Blocks[0], stride=1)\n",
        "        self.conv1 = ResizeConv2d(64, nc, kernel_size=3, scale_factor=2)\n",
        "\n",
        "    def _make_layer(self, BasicBlockDec, planes, num_Blocks, stride):\n",
        "        strides = [stride] + [1]*(num_Blocks-1)\n",
        "        layers = []\n",
        "        for stride in reversed(strides):\n",
        "            layers += [BasicBlockDec(self.in_planes, stride)]\n",
        "        self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.linear(z)\n",
        "        x = x.view(z.size(0), 512, 1, 1)\n",
        "        x = F.interpolate(x, scale_factor=7)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer1(x)\n",
        "        x = F.interpolate(x, size=(112,112), mode='bilinear')\n",
        "        x = torch.sigmoid(self.conv1(x))\n",
        "        x = x.view(x.size(0), 3, 224, 224)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "gHmCoxpPK_nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim):\n",
        "        # super(VAE, self).__init__()\n",
        "        super().__init__()\n",
        "        self.encoder = ResNet18Enc(z_dim=z_dim)\n",
        "        self.decoder = ResNet18Dec(z_dim=z_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, logvar = self.encoder(x)\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        x = self.decoder(z)\n",
        "        return x, mean, logvar\n",
        "    \n",
        "    @staticmethod\n",
        "    def reparameterize(mean, logvar):\n",
        "        std = torch.exp(logvar / 2) # in log-space, squareroot is divide by two\n",
        "        epsilon = torch.randn_like(std).to(device)\n",
        "        return epsilon * std + mean\n"
      ],
      "metadata": {
        "id": "9zS9BYXEWdn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(recon_x, x, mu, logvar):\n",
        "  BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "  KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "  return BCE + KLD"
      ],
      "metadata": {
        "id": "tmyHk6KLdEm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customized dataloaders and checkpoint saving"
      ],
      "metadata": {
        "id": "XWfkSizEImlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model checkpoint saving and loading\n",
        "def save_checkpoint(state, is_best, checkpoint_path, best_model_path):\n",
        "\tc_path = checkpoint_path\n",
        "\ttorch.save(state, c_path)\n",
        "\tif is_best:\n",
        "\t\tbest_mpath = best_model_path\n",
        "\t\tshutil.copyfile(c_path, best_mpath)\n",
        "\n",
        "def load_model(best_model_path, checkpoint_path, model, optimizer, checkpoint_type, train_loss_key, val_loss_key):\n",
        "\n",
        "\tcurrent_ckp = torch.load(checkpoint_path)\n",
        "\tbest_ckp = torch.load(best_model_path)\n",
        "\n",
        "\tif checkpoint_type == 'current':\n",
        "\t\tmodel.load_state_dict(current_ckp['state_dict'])\n",
        "\t\toptimizer.load_state_dict(current_ckp['optimizer'])\n",
        "\t\tepoch = current_ckp['epoch']\n",
        "\t\ttrainloss = current_ckp[train_loss_key]\n",
        "\t\tvalloss = current_ckp[val_loss_key]\n",
        "\t\tmin_valloss = best_ckp[val_loss_key]\n",
        "\n",
        "\telif checkpoint_type == 'best':\n",
        "\t\tmodel.load_state_dict(best_ckp['state_dict'])\n",
        "\t\toptimizer.load_state_dict(best_ckp['optimizer'])\n",
        "\t\tepoch = best_ckp['epoch']\n",
        "\t\ttrainloss = best_ckp[train_loss_key]\n",
        "\t\tvalloss = best_ckp[val_loss_key]\n",
        "\t\tmin_valloss = valloss\n",
        "\n",
        "\treturn model, optimizer, epoch, trainloss, valloss, min_valloss\n",
        "\n",
        "def load_checkpoint(best_model_path, checkpoint_path, model, optimizer, checkpoint_type):\n",
        "    train_loss_key, val_loss_key = 'train loss','val loss'\n",
        "    model, optimizer, epoch, trainloss, valloss, min_valloss = load_model(best_model_path, checkpoint_path, model, optimizer, checkpoint_type, train_loss_key, val_loss_key)\n",
        "    print(\"optimizer = \", optimizer)\n",
        "    print(\"start_epoch = \", epoch)\n",
        "    print(f'train loss -> {trainloss}')\n",
        "    print(f'val loss -> {valloss}')\n",
        "    print(f'min val loss -> {min_valloss}')\n",
        "    \n",
        "    return model, optimizer, trainloss, valloss, min_valloss"
      ],
      "metadata": {
        "id": "ae61ecxfCwcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset for Handler option 1: Using torchvision default ImageFolder, if image are catagorized in specific folders. For example, classification tasks: dog, cat, zebra, etc.\n",
        "def train_val_dataset(dataset, val_split=0.3):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "    return datasets\n",
        "\n",
        "# Handler option 2: Customized Dataset Folder handler, if image are not categorized in specific folders. For example, regression tasks: house price prediction from house image.\n",
        "# The handler will obtain file path from dataframe.\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "        self.list_ID = self.dataframe[['your label here']]\n",
        "        self.transform = transforms.Compose([transforms.CenterCrop(224)])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.list_ID)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        data_path = self.list_ID.iloc[index,0]\n",
        "        X = self.transform(read_image(data_path)/255)\n",
        "        return X"
      ],
      "metadata": {
        "id": "wym3pDaA_PZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'Define directory'\n",
        "# For Handler option 1:\n",
        "trainroot = \"/content/train/\"\n",
        "testroot = \"/content/test/\"\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.CenterCrop(224)])\n",
        "traindata = ImageFolder(trainroot, transform=transform)\n",
        "testdata = ImageFolder(testroot, transform=transform)\n",
        "\n",
        "# For Handler option 2:\n",
        "trainroot = '/content/train.csv'\n",
        "testroot = '/content/test.csv'\n",
        "traindata = CustomImageDataset(pd.read_csv(trainroot))\n",
        "testdata = CustomImageDataset(pd.read_csv(testroot))\n",
        "\n",
        "# 'Only prepare train and validation dataset, test=val'\n",
        "print(f'train set: {len(traindata)}')\n",
        "print(f'val/test set: {len(testdata)}')\n",
        "\n",
        "# Saving model checkpoint\n",
        "checkpoint_path = f'/content/model/checkpoint.pth'\n",
        "best_model_path = f'/content/model/bestmodel.pth'\n",
        "\n",
        "'Initialize\n",
        "# log files\n",
        "log_df = pd.DataFrame({'trainloss': [], 'valloss': []})\n",
        "epoch_num = 50\n",
        "batch_size = 10\n",
        "model = ResUnet18().to(device)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "min_valloss = np.Inf\n",
        "# save best model using validation loss\n",
        "\n",
        "train_loader = DataLoader(traindata,batch_size, shuffle=True)\n",
        "test_loader = DataLoader(testdata,batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "f_I5VszKeD6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e14357d-2d1c-4212-c1bb-dd5c8fea419c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: 2280\n",
            "val/test set: 1120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'training status key'\n",
        "# 'init -> model training start from epoch 1\n",
        "# 'continue' -> model training start from last stopped epoch\n",
        "\n",
        "'checkpoint_type'\n",
        "# 'current' -> model training start from epoch 1 ('init), or start from last stopped epoch\n",
        "# 'best' -> model training start from last saved checkpoint with best validation loss. (used for test)\n",
        "training_status = 'init'\n",
        "checkpoint_type = 'current'\n",
        "# epoch_num = 33"
      ],
      "metadata": {
        "id": "2km4YqVqMNc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if training_status == 'continue':\n",
        "  model, optimizer, trainloss, valloss, min_valloss = load_checkpoint(best_model_path, checkpoint_path, model, optimizer, checkpoint_type=checkpoint_type)"
      ],
      "metadata": {
        "id": "vS_VbxotMLpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "ITLpP8ExI4uP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'train and val in every epoch'\n",
        "\n",
        "for epoch in range(epoch_num):\n",
        "  cumutrainloss, cumuvalloss = 0,0\n",
        "  model.train()\n",
        "  \n",
        "  with tqdm(train_loader) as tepoch:\n",
        "    for x in tepoch:\n",
        "\n",
        "      tepoch.set_description(f\"Epoch {epoch+1}\")\n",
        "      x = Variable(x).to(device)\n",
        "\n",
        "      # Clear gradients\n",
        "      optimizer.zero_grad()\n",
        "      recon_x, mu, logvar = model.forward(x)\n",
        "      loss = loss_func(recon_x, x, mu, logvar)\n",
        "      cumutrainloss += loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      tepoch.set_postfix(train_loss=loss.item())\n",
        "      sleep(0.1)\n",
        "  \n",
        "  scheduler.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    with tqdm(test_loader) as vepoch:\n",
        "\n",
        "      for x in vepoch:\n",
        "\n",
        "        x = Variable(x).to(device)\n",
        "        vresult = model.forward(x)\n",
        "        vresult, vmu, vlogvar = model.forward(x)\n",
        "        loss = loss_func(vresult, x, vmu, vlogvar)\n",
        "\n",
        "        cumuvalloss += loss.item()\n",
        "\n",
        "        vepoch.set_postfix(val_loss=loss.item())\n",
        "        sleep(0.1)\n",
        "\n",
        "  trainloss = cumutrainloss/len(train_loader)\n",
        "  trainloss = trainloss.clone().detach().cpu()\n",
        "  valloss = cumuvalloss/len(test_loader)\n",
        "\n",
        "  log_df = log_df.append({'trainloss': trainloss, 'valloss': valloss}, ignore_index=True)\n",
        "  \n",
        "  if (epoch+1)%1 == 0:\n",
        "    print(f'Epoch [{epoch+1}/{epoch_num}]: Train loss= {trainloss:.4f}, Val loss= {valloss:.4f}')\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'train loss': trainloss,\n",
        "        'val loss': valloss,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()}\n",
        "  \n",
        "  save_checkpoint(checkpoint, False, checkpoint_path, best_model_path)\n",
        "  \n",
        "  if valloss <= min_valloss:\n",
        "    print(f'Train loss decreased ({min_valloss:.4f} --> {valloss:.4f}). Saving model ...')\n",
        "    # save checkpoint as best model\n",
        "    save_checkpoint(checkpoint, True, checkpoint_path, best_model_path)\n",
        "    min_valloss = valloss\n",
        "\n",
        "  log_df.astype('float32').to_csv(f'/content/log.csv')\n",
        "  \n",
        "print('Finished training')"
      ],
      "metadata": {
        "id": "devj98RMMm3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "pONlc123Mya5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test using validation set, could prepare another test set as an option.\n",
        "i = 0\n",
        "with torch.no_grad():\n",
        "  for x in test_loader:\n",
        "    x = Variable(x).to(device)\n",
        "    vresult, vmu, vlogvar = model.forward(x)\n",
        "    utils.save_image(vresult.data, f'/content/result/{i}.png', normalize=True)\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "GTXStOvKWy7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cU6bC-SrisNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "evkhuyhZCiA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}